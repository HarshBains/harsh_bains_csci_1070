{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "76ff7a22-8389-4582-9892-5cd769d25930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import DataFrame, Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a762cf-9c2a-4bed-8bd4-e176857754b1",
   "metadata": {},
   "source": [
    "# BROAD PREPROCESSING\n",
    "\n",
    "I want to manually encode binary columns, assigning the Y and N (or equivalent) values to 1 and 0, respectively. For string columns such as \"EDUCATION\", however, I will use one hot encoding to minimize potential errors.\n",
    "\n",
    "Null values will also need to be handled effectively. I will replace all null values in binary or ordinal columns with the column's mode, since that means that there is essentially a 50% chance to get the entry \"right,\" but I will use the column's median for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "4539e03c-f11a-429f-8e9c-f12b3636b78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ind_ID</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>Car_Owner</th>\n",
       "      <th>Propert_Owner</th>\n",
       "      <th>CHILDREN</th>\n",
       "      <th>Annual_income</th>\n",
       "      <th>Type_Income</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>Marital_status</th>\n",
       "      <th>Housing_type</th>\n",
       "      <th>Birthday_count</th>\n",
       "      <th>Employed_days</th>\n",
       "      <th>Mobile_phone</th>\n",
       "      <th>Work_Phone</th>\n",
       "      <th>Phone</th>\n",
       "      <th>EMAIL_ID</th>\n",
       "      <th>Type_Occupation</th>\n",
       "      <th>Family_Members</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5008827</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-18772.0</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5009744</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-13557.0</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5009746</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5009749</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-13557.0</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5009752</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-13557.0</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5009753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-13557.0</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5009754</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-13557.0</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5009894</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-22134.0</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5010864</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-18173.0</td>\n",
       "      <td>-678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5010868</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-18173.0</td>\n",
       "      <td>-678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ind_ID GENDER Car_Owner Propert_Owner  CHILDREN  Annual_income  \\\n",
       "0  5008827      M         Y             Y         0       180000.0   \n",
       "1  5009744      F         Y             N         0       315000.0   \n",
       "2  5009746      F         Y             N         0       315000.0   \n",
       "3  5009749      F         Y             N         0            NaN   \n",
       "4  5009752      F         Y             N         0       315000.0   \n",
       "5  5009753    NaN         Y             N         0       315000.0   \n",
       "6  5009754      F         Y             N         0       315000.0   \n",
       "7  5009894      F         N             N         0       180000.0   \n",
       "8  5010864      M         Y             Y         1       450000.0   \n",
       "9  5010868      M         Y             Y         1       450000.0   \n",
       "\n",
       "            Type_Income                      EDUCATION Marital_status  \\\n",
       "0             Pensioner               Higher education        Married   \n",
       "1  Commercial associate               Higher education        Married   \n",
       "2  Commercial associate               Higher education        Married   \n",
       "3  Commercial associate               Higher education        Married   \n",
       "4  Commercial associate               Higher education        Married   \n",
       "5             Pensioner               Higher education        Married   \n",
       "6  Commercial associate               Higher education        Married   \n",
       "7             Pensioner  Secondary / secondary special        Married   \n",
       "8  Commercial associate  Secondary / secondary special        Married   \n",
       "9             Pensioner  Secondary / secondary special        Married   \n",
       "\n",
       "        Housing_type  Birthday_count  Employed_days  Mobile_phone  Work_Phone  \\\n",
       "0  House / apartment        -18772.0         365243             1           0   \n",
       "1  House / apartment        -13557.0           -586             1           1   \n",
       "2  House / apartment             NaN           -586             1           1   \n",
       "3  House / apartment        -13557.0           -586             1           1   \n",
       "4  House / apartment        -13557.0           -586             1           1   \n",
       "5  House / apartment        -13557.0           -586             1           1   \n",
       "6  House / apartment        -13557.0           -586             1           1   \n",
       "7  House / apartment        -22134.0         365243             1           0   \n",
       "8  House / apartment        -18173.0           -678             1           0   \n",
       "9  House / apartment        -18173.0           -678             1           0   \n",
       "\n",
       "   Phone  EMAIL_ID Type_Occupation  Family_Members  label  \n",
       "0      0         0             NaN               2      1  \n",
       "1      1         0             NaN               2      1  \n",
       "2      1         0             NaN               2      1  \n",
       "3      1         0             NaN               2      1  \n",
       "4      1         0             NaN               2      1  \n",
       "5      1         0             NaN               2      1  \n",
       "6      1         0             NaN               2      1  \n",
       "7      0         0             NaN               2      1  \n",
       "8      1         1      Core staff               3      1  \n",
       "9      1         1      Core staff               3      1  "
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the Credit Card dataset\n",
    "credit_base = pd.read_csv(\"Credit_card.csv\")\n",
    "labels = pd.read_csv(\"Credit_card_label.csv\")\n",
    "\n",
    "# Merge Credit_card.csv and Credit_card_label.csv so that there's an additional column representing whether the entry was accepted or denied\n",
    "# for a credit card\n",
    "credit_df = pd.merge(credit_base, labels, on = 'Ind_ID')\n",
    "\n",
    "credit_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "ddc5ac07-e463-4dc0-9619-264cfc7f8366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ind_ID</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>Car_Owner</th>\n",
       "      <th>Propert_Owner</th>\n",
       "      <th>CHILDREN</th>\n",
       "      <th>Annual_income</th>\n",
       "      <th>Birthday_count</th>\n",
       "      <th>Employed_days</th>\n",
       "      <th>Mobile_phone</th>\n",
       "      <th>Work_Phone</th>\n",
       "      <th>...</th>\n",
       "      <th>Laborers</th>\n",
       "      <th>Low-skill Laborers</th>\n",
       "      <th>Managers</th>\n",
       "      <th>Medicine staff</th>\n",
       "      <th>Private service staff</th>\n",
       "      <th>Realty agents</th>\n",
       "      <th>Sales staff</th>\n",
       "      <th>Secretaries</th>\n",
       "      <th>Security staff</th>\n",
       "      <th>Waiters/barmen staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5008827</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>-18772.0</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5009744</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>-13557.0</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5009746</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>-15661.5</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5009749</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>166500.0</td>\n",
       "      <td>-13557.0</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5009752</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>-13557.0</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5009753</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>-13557.0</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5009754</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>-13557.0</td>\n",
       "      <td>-586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5009894</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>-22134.0</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5010864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>-18173.0</td>\n",
       "      <td>-678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5010868</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>-18173.0</td>\n",
       "      <td>-678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ind_ID  GENDER  Car_Owner  Propert_Owner  CHILDREN  Annual_income  \\\n",
       "0  5008827     1.0          1              1         0       180000.0   \n",
       "1  5009744     2.0          1              2         0       315000.0   \n",
       "2  5009746     2.0          1              2         0       315000.0   \n",
       "3  5009749     2.0          1              2         0       166500.0   \n",
       "4  5009752     2.0          1              2         0       315000.0   \n",
       "5  5009753     2.0          1              2         0       315000.0   \n",
       "6  5009754     2.0          1              2         0       315000.0   \n",
       "7  5009894     2.0          2              2         0       180000.0   \n",
       "8  5010864     1.0          1              1         1       450000.0   \n",
       "9  5010868     1.0          1              1         1       450000.0   \n",
       "\n",
       "   Birthday_count  Employed_days  Mobile_phone  Work_Phone  ...  Laborers  \\\n",
       "0        -18772.0         365243             1           0  ...     False   \n",
       "1        -13557.0           -586             1           1  ...     False   \n",
       "2        -15661.5           -586             1           1  ...     False   \n",
       "3        -13557.0           -586             1           1  ...     False   \n",
       "4        -13557.0           -586             1           1  ...     False   \n",
       "5        -13557.0           -586             1           1  ...     False   \n",
       "6        -13557.0           -586             1           1  ...     False   \n",
       "7        -22134.0         365243             1           0  ...     False   \n",
       "8        -18173.0           -678             1           0  ...     False   \n",
       "9        -18173.0           -678             1           0  ...     False   \n",
       "\n",
       "   Low-skill Laborers  Managers  Medicine staff  Private service staff  \\\n",
       "0               False     False           False                  False   \n",
       "1               False     False           False                  False   \n",
       "2               False     False           False                  False   \n",
       "3               False     False           False                  False   \n",
       "4               False     False           False                  False   \n",
       "5               False     False           False                  False   \n",
       "6               False     False           False                  False   \n",
       "7               False     False           False                  False   \n",
       "8               False     False           False                  False   \n",
       "9               False     False           False                  False   \n",
       "\n",
       "   Realty agents  Sales staff  Secretaries  Security staff  \\\n",
       "0          False        False        False           False   \n",
       "1          False        False        False           False   \n",
       "2          False        False        False           False   \n",
       "3          False        False        False           False   \n",
       "4          False        False        False           False   \n",
       "5          False        False        False           False   \n",
       "6          False        False        False           False   \n",
       "7          False        False        False           False   \n",
       "8          False        False        False           False   \n",
       "9          False        False        False           False   \n",
       "\n",
       "   Waiters/barmen staff  \n",
       "0                 False  \n",
       "1                 False  \n",
       "2                 False  \n",
       "3                 False  \n",
       "4                 False  \n",
       "5                 False  \n",
       "6                 False  \n",
       "7                 False  \n",
       "8                 False  \n",
       "9                 False  \n",
       "\n",
       "[10 rows x 52 columns]"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the function that standardizes the given column, with type hinting and a default argument when appropriate\n",
    "def std_gender(col: Series = credit_df['GENDER']) -> Series:\n",
    "    m = {'M' : 1, 'F' : 2}\n",
    "    col = col.map(m)\n",
    "    col = col.fillna(col.mode().iloc[0]) # I'm replacing all null values with the mode since the responses in this column are binary; the\n",
    "    # most commonly occurring value makes sense to substitute null with as we proverbially have a 50-50 shot of getting the answer right\n",
    "    return col\n",
    "\n",
    "credit_df['GENDER'] = std_gender()\n",
    "\n",
    "# Define the function that standardizes the given column, with type hinting and a default argument when appropriate\n",
    "def std_car(col: Series = credit_df['Car_Owner']) -> Series:\n",
    "    m = {'Y' : 1, 'N' : 2}\n",
    "    col = col.map(m)\n",
    "    col = col.fillna(col.mode().iloc[0]) # I'm replacing all null values with the mode since the responses in this column are binary; the\n",
    "    # most commonly occurring value makes sense to substitute null with as we proverbially have a 50-50 shot of getting the answer right\n",
    "    return col\n",
    "\n",
    "credit_df['Car_Owner'] = std_car()\n",
    "\n",
    "# Define the function that standardizes the given column, with type hinting and a default argument when appropriate\n",
    "def std_property(col: Series = credit_df['Propert_Owner']) -> Series:\n",
    "    m = {'Y' : 1, 'N' : 2}\n",
    "    col = col.map(m)\n",
    "    col = col.fillna(col.mode().iloc[0]) # I'm replacing all null values with the mode since the responses in this column are binary; the\n",
    "    # most commonly occurring value makes sense to substitute null with as we proverbially have a 50-50 shot of getting the answer right\n",
    "    return col\n",
    "\n",
    "credit_df['Propert_Owner'] = std_property()\n",
    "\n",
    "# One hot encode all categorical string columns\n",
    "def encode(col: Series, df: DataFrame = credit_df) -> DataFrame:\n",
    "    temp = pd.get_dummies(df[col])\n",
    "    df = df.drop(columns = [col])\n",
    "    df = df.join(temp)\n",
    "    return df\n",
    "\n",
    "\n",
    "cols = ['Type_Income', 'EDUCATION', 'Marital_status', 'Housing_type', 'Type_Occupation']\n",
    "\n",
    "for col in cols:\n",
    "    credit_df = encode(col, credit_df)\n",
    "\n",
    "# For miscellaneous null cleaning\n",
    "def null_sub(df: DataFrame = credit_df) -> DataFrame:\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['int64', 'float64']: # Numerical columns\n",
    "            median = df[col].median()\n",
    "            df[col] = df[col].fillna(median)\n",
    "        elif df[col].dtype == 'object': # Categorical columns\n",
    "            mode = df[col].mode().iloc[0]\n",
    "            df[col] = df[col].fillna(mode)\n",
    "    return df\n",
    "\n",
    "credit_df = null_sub()\n",
    "\n",
    "credit_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e644443d-13a8-4c6b-9c40-bb6c7697a84b",
   "metadata": {},
   "source": [
    "# UNIVARIATE LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "0666f9a5-4157-4341-851a-6439cd999844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.01587415490612476\n"
     ]
    }
   ],
   "source": [
    "# X is what we are using to predict, while y is what we are predicting. Univariate linear regression only involves one independent variable,\n",
    "# so I chose the 'Annual_income' column since it logically seems like the predominant factor deciding the label, other than residence.\n",
    "X = credit_df[['Annual_income']]\n",
    "y = credit_df['label']\n",
    "\n",
    "# Conduct the train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42) # Set to 42 for congruence with our class \n",
    "# notes; I like 02 as well, though :)\n",
    "\n",
    "# Create and fit the linear regression model\n",
    "lReg = LinearRegression()\n",
    "lReg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "lPred = lReg.predict(X_test)\n",
    "\n",
    "# Check accuracy; abhorrent\n",
    "r2 = lReg.score(X_test, y_test)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a728af2a-6ba4-40c9-ab87-0e2df18c1692",
   "metadata": {},
   "source": [
    "### TAKEAWAYS\n",
    "\n",
    "An R-squared score of -0.016 is genuienly terrible; it seems as though annual_income alone is not enough to predict whether someone will receive a credit card. With so many different variables at play, it lines up that there are other considerations that need to be made when predicting 'label.' Regardless, perhaps the most damning reason for univariate linear regression's failure stems not from \"univariate,\" but from \"linear.\" We are trying to predict a binary outcome-- whether someone will be approved for a credit card or not, yes or no-- which linear regression is not suitable for, since it is liable to produce predictions outside our range of acceptable answers, which is [0,1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c33ed0a-9124-4ff7-b2af-99c068bd31a7",
   "metadata": {},
   "source": [
    "# K-NEAREST NEIGHBOR (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "f9c17d30-f1f4-4a66-a657-d166fe5ad728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075268817204301\n"
     ]
    }
   ],
   "source": [
    "# First, we need to establish our train-test split as well as our variables\n",
    "\n",
    "X = credit_df.drop('label', axis = 1)\n",
    "y = credit_df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# Find the optimal K value\n",
    "def optimalNeighbors(X_train, X_test, y_train, y_test) -> int:\n",
    "    maxScore = 0\n",
    "    maxK = 1\n",
    "\n",
    "    for currK in range(1, 100):\n",
    "        knn = KNeighborsClassifier(n_neighbors = currK)\n",
    "        knn.fit(X_train, y_train)\n",
    "        knnPred = knn.predict(X_test)\n",
    "        currScore = knn.score(X_test, y_test)\n",
    "        if (currScore > maxScore):\n",
    "            maxScore = currScore\n",
    "            maxK = currK\n",
    "\n",
    "    return maxK\n",
    "\n",
    "# Establish K\n",
    "k = optimalNeighbors(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Train the KNN model using the optimal number of neighbors found above\n",
    "knn = KNeighborsClassifier(n_neighbors = k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "kPred = knn.predict(X_test)\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6795c2c-2771-4c95-888b-adce8094e78c",
   "metadata": {},
   "source": [
    "### TAKEAWAYS\n",
    "\n",
    "A score of 90.75 is pretty damn good, all things considered; finding the optimal K value seems to have affected our accuracy in a pretty major way. KNN does work far better for predicting deterministic outcomes than univariate linear regression, so this outcome makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3d0b4d-f764-44c8-82ce-ee1702b77be0",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "f268abfa-040e-4baa-bbae-bd15907ebb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9032258064516129"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = credit_df.drop('label', axis = 1)\n",
    "y = credit_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "regression = LogisticRegression(random_state = 42).fit(X_train, y_train)\n",
    "y_predicted = regression.predict(X_test)\n",
    "\n",
    "regression.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac14c4-906f-4d41-a5fe-e924f2fca4fc",
   "metadata": {},
   "source": [
    "### TAKEAWAYS\n",
    "\n",
    "A score of 90.3 is still good, albeit slightly less than KNN. Still, logistic regression is far superior to linear regression for this use case, which, of course, is to be expected, as logistic regression is far more suited to predicting binary or otherwise deterministic outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc835f9-f88a-4390-8b81-af925b03a536",
   "metadata": {},
   "source": [
    "# NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "05d17533-83d1-483a-95b3-b955465a41a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.779045750960979e+18\n"
     ]
    }
   ],
   "source": [
    "X = credit_df.drop('label', axis = 1)\n",
    "y = credit_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "# Use StandardScaler() so that the mean is 0 and the standard deviation is 1, making the data more centralized\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "# Use univariate linear regression on the newly normalized data\n",
    "lReg = LinearRegression()\n",
    "lReg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "lPred = lReg.predict(X_test)\n",
    "\n",
    "# Check accuracy\n",
    "r2 = lReg.score(X_test, y_test)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "697d51cf-a83b-4b63-af64-976b18d447fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896774193548387\n"
     ]
    }
   ],
   "source": [
    "# Use KNN using the newly normalized data\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "kPred = knn.predict(X_test)\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "d03d2e90-3de6-48b1-8fcb-67b091fbf127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9064516129032258"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use logistic regression using the newly normalized data\n",
    "\n",
    "regression = LogisticRegression(random_state = 42).fit(X_train, y_train)\n",
    "y_predicted = regression.predict(X_test)\n",
    "\n",
    "regression.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613dd4c-b939-49c7-aa44-780db9b80d1c",
   "metadata": {},
   "source": [
    "### TAKEAWAYS\n",
    "\n",
    "Interestingly, it seems as though normalizing the data made univariate linear regression and KNN perform slightly worse, while logistic regression performed marginally better. I am unsure what this is indicative of-- do you have any thoughts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b084f7f7-b8e3-476c-a912-707c02f48e6a",
   "metadata": {},
   "source": [
    "# WHAT METRIC IS MOST CONDUCIVE?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e119979a-a91c-4111-b471-d2fd1827bcb2",
   "metadata": {},
   "source": [
    "For our purposes, there's three primary metrics that measure our dataset's performance: accuracy, precision, and recall. Let's go through each one.\n",
    "\n",
    "Accuracy is simply the number of correct predictions divided by the number of total predictions. This seems pretty accurate on paper; however, this can be skewed if one prediction heavily outweighs all others, which is more likely if not liable to occur in situations we are predicting a binary outcome. To demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "6b6b59e2-a484-421c-86bd-f135f9f60dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1373\n",
       "1     175\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c984b4a0-12ec-4bb7-a253-5d63bfb7313c",
   "metadata": {},
   "source": [
    "Above, you can see that far, far more people were denied a credit card than those who were accepted. In these cases, accuracy can prove to be misleading.\n",
    "\n",
    "What about precision, then? Well, precision is the number of true positive predictions (i.e., values which were predicted to be positive and actually were) divided by the total number of positives, both true and false. This can prove useful in cases where we wish to minimize the number of false credit card approvals, which would seem applicable in times where credit card fraud is a genuine concern.\n",
    "\n",
    "It's still worth discussing, recall, however, which is the number of true positives divided by the total actual positives (which not only includes true positives, but also values the model flagged as negative, which were actually positive-- false negatives!). This metric can aid us in minimizing the number of rejections of valid applicants, which would seem applicable in times where the bank has a need to establish new credit lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503fd18e-a80d-41fb-9845-85bdd95b3e45",
   "metadata": {},
   "source": [
    "### TAKEAWAYS\n",
    "\n",
    "With the above in mind, precision and recall seem like the most conducive metrics for our purposes, with the former helping us identify false positives and the latter helping us identify false negatives. For a successful bank, preventing fraud is definitely high on the priority list; as such, precision would be the most helpful metric for the institution, as well as us, to look at when measuring the dataset's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
